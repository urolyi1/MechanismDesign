{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleHospital:\n",
    "    def __init__(self, n_types, dist_lst):\n",
    "        ''' Takes in number of pair types along with a list of functions that\n",
    "        generate the number of people in that hospital with pair type.\n",
    "        '''\n",
    "        self.n_types = n_types\n",
    "        self.dists = dist_lst\n",
    "    def generate(self, batch_size):\n",
    "        '''generate a report from this hospital'''\n",
    "        X = np.zeros((batch_size, self.n_types))\n",
    "        for i, dist in enumerate(self.dists):\n",
    "            X[:, i] = dist(size=batch_size)\n",
    "        return X\n",
    "        \n",
    "class ReportGenerator:\n",
    "    def __init__(self, hos_lst, single_report_shape):\n",
    "        self.hospitals = hos_lst\n",
    "        self.single_shape = single_report_shape\n",
    "    def generate_report(self, batch_size):\n",
    "        X = np.zeros((batch_size,) + self.single_shape)\n",
    "        for i, hos in enumerate(self.hospitals):\n",
    "            X[:, i, :] = hos.generate(batch_size)\n",
    "        yield X\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randint(low, high):\n",
    "    return lambda size: np.random.randint(low, high, size)\n",
    "\n",
    "def create_simple_generator(low_lst_lst, high_lst_lst, n_hos, n_types):\n",
    "    hos_lst = []\n",
    "    for h in range(n_hos):\n",
    "        tmp_dist_lst = []\n",
    "        for t in range(n_types):\n",
    "            tmp_dist_lst.append(randint(low_lst_lst[h][t], high_lst_lst[h][t]))\n",
    "        hos_lst.append(SingleHospital(n_types, tmp_dist_lst))\n",
    "    gen = ReportGenerator(hos_lst, (n_hos, n_types))\n",
    "    return gen\n",
    "\n",
    "low_lst_lst = [[5, 10],[20, 40],[40, 80]]\n",
    "high_lst_lst = [[10, 20], [40, 80], [80, 160]]\n",
    "gen = create_simple_generator(low_lst_lst, high_lst_lst, 3, 2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_u_mask(compat_lst, n_types, n_hos):\n",
    "    '''\n",
    "    Create mask matrix that will only reward valid matchings making the rest 0\n",
    "    return shape (n_hos, n_types, n_types)\n",
    "    '''\n",
    "    mask = np.zeros([n_hos, n_types, n_types])\n",
    "    print(mask.shape)\n",
    "    for t1, t2 in compat_lst:\n",
    "        mask[:, t1, t2] = 1.0\n",
    "        mask[:, t2, t1] = 1.0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Uro\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "learn_rate = 0.01\n",
    "n_hos = 3\n",
    "n_types = 2\n",
    "batch_size = 10\n",
    "\n",
    "n_features = n_hos * n_types\n",
    "n_out = n_hos * n_types * n_types \n",
    "\n",
    "init = tf.keras.initializers.glorot_uniform()\n",
    "\n",
    "num_layers = 5\n",
    "\n",
    "neurons = [n_features, 100, 100, 100, n_out]\n",
    "\n",
    "weights = []\n",
    "biases = []\n",
    "\n",
    "activation = [tf.nn.tanh] * (num_layers - 1) + [tf.nn.tanh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating weights for layer: 1\n",
      "[6, 100]\n",
      "Creating weights for layer: 2\n",
      "[100, 100]\n",
      "Creating weights for layer: 3\n",
      "[100, 100]\n",
      "Creating weights for layer: 4\n",
      "[100, 12]\n",
      "Creating biases for layer: 1\n",
      "Creating biases for layer: 2\n",
      "Creating biases for layer: 3\n",
      "Creating biases for layer: 4\n"
     ]
    }
   ],
   "source": [
    "# Creating input layer weights\n",
    "print(\"Creating weights for layer: 1\")\n",
    "print([neurons[0], neurons[1]])\n",
    "weights.append(tf.compat.v1.get_variable('w_a_1', [neurons[0], neurons[1]], initializer=init))\n",
    "\n",
    "\n",
    "# Creating hidden layers\n",
    "for i in range(1, num_layers - 2):\n",
    "    print(\"Creating weights for layer: {}\".format(i+1))\n",
    "    print([neurons[i], neurons[i + 1]])\n",
    "    weights.append(tf.compat.v1.get_variable('w_a_' + str(i+1), [neurons[i], neurons[i + 1]], initializer=init))\n",
    "\n",
    "# need two outputs\n",
    "print(\"Creating weights for layer: {}\".format(num_layers - 1))\n",
    "print([neurons[-2], neurons[-1]])\n",
    "weights.append(tf.compat.v1.get_variable('w_a_' + str(num_layers - 1), [neurons[-2], neurons[-1]], initializer=init))\n",
    "w_prime = tf.compat.v1.get_variable('wi_a_' + str(num_layers - 1), [neurons[-2], neurons[-1]], initializer=init)\n",
    "\n",
    "\n",
    "# Biases\n",
    "for i in range(num_layers - 2):\n",
    "    print(\"Creating biases for layer: {}\".format(i+1))\n",
    "    biases.append(tf.compat.v1.get_variable('b_a_' + str(i+1), [neurons[i + 1]], initializer=init))\n",
    "\n",
    "print(\"Creating biases for layer: {}\".format(num_layers - 1))\n",
    "biases.append(tf.compat.v1.get_variable('b_a_' + str(num_layers - 1), [neurons[-1]], initializer=init))\n",
    "b_prime = tf.compat.v1.get_variable('bi_a_' + str(num_layers - 1), [neurons[-1]], initializer=init)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(X):\n",
    "    x_in = tf.reshape(X, [-1, neurons[0]])\n",
    "\n",
    "    a = tf.nn.relu(tf.matmul(x_in, weights[0]) + biases[0], 'alloc_act_0')\n",
    "\n",
    "    # push through hidden layers\n",
    "    for i in range(1, num_layers - 2):\n",
    "        a = tf.matmul(a, weights[i]) + biases[i]\n",
    "        a = tf.nn.relu(a, 'alloc_act_' + str(i))\n",
    "\n",
    "    # final layer\n",
    "    pair = tf.matmul(a, weights[-1]) + biases[-1]\n",
    "    pool = tf.matmul(a, w_prime) + b_prime\n",
    "\n",
    "    # Softmax over pairs and total pool\n",
    "    pair = tf.reshape(tf.nn.softmax(tf.reshape(pair, [-1, n_types * n_hos, n_types]), axis=-1), [-1, n_hos, n_types, n_types])\n",
    "    pool = tf.reshape(tf.nn.softmax(tf.reshape(pool, [-1, n_types * n_hos, n_types]), axis=1), [-1, n_hos, n_types, n_types])\n",
    "\n",
    "    ## Weighting softmax values ##\n",
    "\n",
    "    # Weight softmax values by hospital's reported needs\n",
    "    pair = tf.math.multiply(pair, tf.reshape(X, [-1, n_hos, n_types, 1]))\n",
    "\n",
    "    # Sums over each hospitals for for all pair types then reshapes to allow broadcasting\n",
    "    tot_reshaped = tf.reshape(tf.math.reduce_sum(tf.reshape(X, [-1, n_hos, n_types]), axis=1), [-1, 1, 1, n_types])\n",
    "\n",
    "    # Weight softmax values by total available pairs in pool\n",
    "    pool = tf.math.multiply(pool, tot_reshaped)\n",
    "\n",
    "    # Floor of minimum of two allocations\n",
    "    alloc = tf.math.floor(tf.math.minimum(pair, pool))\n",
    "    return alloc\n",
    "def create_misreports(x, curr_mis, self_mask):\n",
    "    '''\n",
    "    x and curr_mis should have dimensions (B, h, p)\n",
    "    combined and og has dimensions (n_hos, batch_size, n_hos, n_types)\n",
    "    '''\n",
    "    tiled_curr_mis = tf.tile(tf.expand_dims(curr_mis, 0), [n_hos, 1, 1, 1])\n",
    "    og_tiled = tf.reshape(tf.tile(x, [n_hos, 1, 1]), [n_hos, -1, n_hos, n_types])\n",
    "    \n",
    "    # Filter original reports to only keep reports from all other hospitals\n",
    "    other_hos = og_tiled * (1 - self_mask)\n",
    "    \n",
    "    # Filter reports to only keep the mis reports\n",
    "    only_mis = tiled_curr_mis * self_mask\n",
    "    \n",
    "    # Add the two to get inputs where only one hospital misreports\n",
    "    combined = only_mis + other_hos\n",
    "    return combined, og_tiled\n",
    "\n",
    "def compute_util(alloc, mask, internal=None):\n",
    "    if internal is None:\n",
    "        return tf.reduce_sum(tf.multiply(alloc, mask), axis=(2, 3))\n",
    "    else:\n",
    "        mech_util = tf.reshape(tf.reduce_sum(tf.multiply(alloc, mask), axis=(2, 3)), [n_hos, -1, n_hos])\n",
    "        return mech_util + compute_internal_util(internal)\n",
    "def compute_internal_util(internal):\n",
    "    '''\n",
    "    internal has dim [n_hos, batch_size, n_hos, n_types]\n",
    "    '''\n",
    "    return tf.reduce_min(internal, axis=3)\n",
    "def compute_internal(misreports, og):\n",
    "    ''' Computes the difference between '''\n",
    "    return (og - misreports) #maybe just keep the specific misreport bidder's difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# This mask is to manipulate the reports and will only have 1 for the specific hospital misreporting\n",
    "self_mask = np.zeros([n_hos, batch_size, n_hos, n_types])\n",
    "self_mask[np.arange(n_hos), :, np.arange(n_hos), :] = 1.0\n",
    "\n",
    "# This mask will only count the utility from the specific hospital that is misreporting\n",
    "mis_u_mask = np.zeros((n_hos, batch_size, n_hos))\n",
    "mis_u_mask[np.arange(n_hos), :, np.arange(n_hos)] = 1.0\n",
    "\n",
    "# Mask to only count valid matchings \n",
    "u_mask = create_u_mask([(0,1)], n_types, n_hos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.compat.v1.placeholder(tf.float32, [batch_size, n_hos * n_types], name='features')\n",
    "curr_mis = tf.reshape(X, [batch_size, n_hos, n_types])\n",
    "\n",
    "# Get misreports and also truthful original reports\n",
    "misreports, og = create_misreports(tf.reshape(X, [batch_size, n_hos, n_types]), curr_mis, self_mask)\n",
    "\n",
    "# Compute non-reported pairs by subtracting misreports from original\n",
    "non_reported = compute_internal(misreports, og)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting it together to get output\n",
    "actual_alloc = feedforward(X)\n",
    "\n",
    "# Run misreports through net to get allocation\n",
    "misreport_alloc = feedforward(tf.reshape(misreports, [-1, n_hos * n_types]))\n",
    "\n",
    "# Utility calculation\n",
    "util = compute_util(actual_alloc, u_mask) # tf.reduce_sum(tf.multiply(alloc, mask), axis=(1, 2, 3))\n",
    "\n",
    "# Compute utility from misreports for specific hospital misreporting only\n",
    "mis_util = tf.reshape(compute_util(misreport_alloc, u_mask, non_reported), [n_hos, batch_size, n_hos]) * mis_u_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.train.AdamOptimizer(learn_rate)\n",
    "init_op = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "#test_in = np.random.randint(1, 100, size=(10, n_features))\n",
    "sess = tf.compat.v1.InteractiveSession()\n",
    "\n",
    "writer = tf.compat.v1.summary.FileWriter('./graphs', sess.graph)\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in = np.reshape(next(gen.generate_report(batch_size)), (10, -1))\n",
    "ex_util = sess.run(util, feed_dict={X:test_in})\n",
    "ex_mis_util = sess.run(mis_util, feed_dict={X:test_in})\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10., 31., 48.],\n",
       "       [ 0.,  0., 43.],\n",
       "       [ 1., 27., 20.],\n",
       "       [ 3., 40., 18.],\n",
       "       [ 0.,  2., 32.],\n",
       "       [ 0., 10., 62.],\n",
       "       [ 0., 13., 28.],\n",
       "       [ 1., 19., 64.],\n",
       "       [ 0.,  3., 43.],\n",
       "       [ 0.,  5., 58.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 3.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0., 31.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0., 27.,  0.],\n",
       "        [ 0., 40.,  0.],\n",
       "        [ 0.,  2.,  0.],\n",
       "        [ 0., 10.,  0.],\n",
       "        [ 0., 13.,  0.],\n",
       "        [ 0., 19.,  0.],\n",
       "        [ 0.,  3.,  0.],\n",
       "        [ 0.,  5.,  0.]],\n",
       "\n",
       "       [[ 0.,  0., 48.],\n",
       "        [ 0.,  0., 43.],\n",
       "        [ 0.,  0., 20.],\n",
       "        [ 0.,  0., 18.],\n",
       "        [ 0.,  0., 32.],\n",
       "        [ 0.,  0., 62.],\n",
       "        [ 0.,  0., 28.],\n",
       "        [ 0.,  0., 64.],\n",
       "        [ 0.,  0., 43.],\n",
       "        [ 0.,  0., 58.]]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_mis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating softmax over total pool ##\n",
    "\n",
    "in_reshaped = np.reshape(test_in, [10, n_hos, n_types])\n",
    "pool_tots = np.sum(in_reshaped, axis=1)\n",
    "\n",
    "# Check for each pair type that the allocated does not exceed the total available\n",
    "for sample in range(10):\n",
    "    for p_type in range(n_types):\n",
    "        print(round(np.sum(ex_pool[sample, :, :, p_type]) - pool_tots[sample, p_type]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating over hospital pair type need\n",
    "\n",
    "# Check allocated amount to each hospital pair type does not exceed need.\n",
    "for sample in range(10):\n",
    "    for hos in range(n_hos):\n",
    "        for p_type in range(n_types):\n",
    "            print(round(np.sum(ex_pair[sample, hos, p_type, :]) - in_reshaped[sample, hos, p_type]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
